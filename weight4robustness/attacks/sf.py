from .attack import Attack


class SignFlippingAttack(Attack):
    """
    Implements the Sign Flipping Attack, a Byzantine attack strategy in which
    the gradient direction is reversed. This attack aims to hinder the convergence
    of distributed learning by flipping the sign of the computed gradient.
    """

    def __init__(self):
        """
        Initializes the SignFlippingAttack class.
        """
        super().__init__()

    def apply(self, inputs, targets, worker, gradient_function, *args, **kwargs):
        """
        Applies the sign flipping attack by computing the gradient for the given inputs and targets,
        and then reversing its direction before passing it to the worker.

        Args:
            inputs (torch.Tensor): Input data.
            targets (torch.Tensor): True target labels.
            worker (Worker): The worker applying the attack.
            gradient_function (callable): Function to compute the gradient given inputs and labels.

        Returns:
            torch.Tensor: Negatively scaled update generated by applying the sign flipping attack.
        """
        # Compute the gradient using the original inputs and targets
        gradient, _, _ = gradient_function(inputs, targets)

        # Return the negated step to reverse the gradient direction
        return -worker.step(gradient)

