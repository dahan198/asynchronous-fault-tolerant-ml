import torch
from .attack import Attack


class IPMAttack(Attack):
    """
    Implements the Inner Product Manipulation (IPM) attack for Byzantine-robust distributed learning.
    This attack perturbs the aggregated updates by applying a controlled negative scaling factor.
    """

    def __init__(self, epsilon=0.1):
        """
        Initializes the IPMAttack class with a specified perturbation magnitude.

        Args:
            epsilon (float): Scaling factor for the attack. Determines the strength of the perturbation.
        """
        super().__init__()
        self.epsilon = epsilon

    def apply(self, honest_updates, weights, *args, **kwargs):
        """
        Applies the IPM attack by negatively scaling the weighted sum of honest updates.

        Args:
            honest_updates (torch.Tensor): Aggregated honest updates from workers.
            weights (torch.Tensor): Weights assigned to honest updates.

        Returns:
            torch.Tensor: Perturbed updates generated by the attack.
        """
        # Compute the weighted sum of honest updates and apply negative scaling
        honest_num = honest_updates.shape[0]
        perturbed_update = -self.epsilon * torch.sum(
            (weights[:honest_num] / weights[:honest_num].sum()) * honest_updates, dim=0
        )
        return perturbed_update
